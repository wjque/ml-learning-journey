# 参数估计的方法

## 最大似然估计 (Maximum Likelyhood Estimation)

考虑一组有 m 个样本的数据集 $\mathbb{X}=\{x^{(1)},x^{(2)},...,x^{(m)} \}$，独立地由分布 $p_{data}(x)$ 生成

我们考虑使用 $p_{model}(x;\boldsymbol{\theta})$ 去估计 $p_{data}(x)$，所以我们需要根据样本得到 $\boldsymbol{\theta}$ 的估计，一种常用的估计是最大似然估计：

$$\boldsymbol{\theta}_{ML}=\argmax \limits_{\boldsymbol{\theta}} p_{model}(\mathbb{X};\boldsymbol{\theta})=\argmax\limits_{\boldsymbol{\theta}}\prod \limits_{i=1}^m p_{model}(x^{(i)};\boldsymbol{\theta})$$

为了避免数值下溢，同时取对数不改变 $\argmax$，所以我们考虑：

$$\boldsymbol{\theta}_{ML}=\argmax_{\boldsymbol{\theta}}\sum\limits_{i=1}^m \log p_{model}(x^{(i)};\boldsymbol{\theta})$$

缩放代价函数不会改变 $\argmax$，我们对上式同时除以 m：

$$\boldsymbol{\theta}_{ML}=\argmax\limits_{\boldsymbol{\theta}}\mathbb{E}_{\bold{x}\sim\hat{p}_{data}}[\log p_{model}(x^{(i)};\boldsymbol{\theta})]$$

我们希望使 $p_{model}(\bold{x};\boldsymbol{\theta})$ 尽可能地逼近 $p_{data}(\bold{x})$，但我们无法知道 $p_{data}(\bold{x})$，根据样本我们只能知道其**经验分布 $\hat{p}_{data}(\bold{x})$**

$\boldsymbol{\theta}_{ML}$ 实际上做的是**使 $p_{model}(\bold{x};\boldsymbol{\theta})$ 逼近 $\hat{p}_{data}(\bold{x})$**，这一点可以从 KL 散度的角度来理解：

$$D_{KL}(\hat{p}_{data}(\bold{x})||p_{model}(\bold{x};\boldsymbol{\theta}))=\mathbb{E}_{\bold{x}\sim\hat{p}_{data}(\bold{x})}[\log \hat{p}_{data}(\bold{x})-\log p_{model}(\bold{x};\boldsymbol{\theta})]$$

$\boldsymbol{\theta}_{ML}$ 在最大化 $\mathbb{E}_{\bold{x}\sim\hat{p}_{data}(\bold{x})}[\log p_{model}(\bold{x};\boldsymbol{\theta})]$，因为 $\hat{p}_{data}(\bold{x})$ 是确定的，所以最大化 $\mathbb{E}_{\bold{x}\sim\hat{p}_{data}(\bold{x})}[\log p_{model}(\bold{x};\boldsymbol{\theta})]$ 也就是在最小化 $D_{KL}(\hat{p}_{data}(\bold{x})||p_{model}(\bold{x};\boldsymbol{\theta}))$，也可以理解为最小化经验分布和定义在模型上概率分布的交叉熵 $H(\hat{p}_{data}(\bold{x}),p_{model}(\bold{x};\boldsymbol{\theta}))$

- 条件对数似然
  - 最大似然估计可以拓展用于估计条件概率，实际上这是最常见的情况，构成了大多数监督学习的基础
  - 用 $\bold{X}$ 表示所有的输入，$\bold{Y}$ 为我们观测到的目标，那么条件最大似然估计为

$$\boldsymbol{\theta}_{ML}=\argmax\limits_{\boldsymbol{\theta}}P(\bold{Y}|\bold{X};\boldsymbol{\theta})$$

若样本是独立同分布的，那么还可以分解为：

$$\boldsymbol{\theta}_{ML}=\argmax\limits_{\boldsymbol{\theta}}\sum\limits_{i=1}^m\log P(\bold{y}^{(i)}|\bold{x}^{(i)};\boldsymbol{\theta})$$

最大似然估计被证明当样本数目 $m\rightarrow\infty$ 时，就收敛率而言是最好的渐进估计，最大似然估计具有一致性的条件：

- 真实分布 $p_{data}$ 必须在模型族 $p_{model}(·|\boldsymbol{\theta})$ 中；
- 真实分布 $p_{data}$ 必须刚好对应一个 $\boldsymbol{\theta}$ 值；

## 贝叶斯估计

频率学派认为待估计的模型参数 $\boldsymbol{\theta}$ 是一个**固定未知**的数，贝叶斯估计则将模型参数 $\boldsymbol{\theta}$ 视为一个**随机变量**，具有先验分布，将样本视为已知条件（频率学派将样本视为随机变量），使用贝叶斯公式恢复我们对 $\boldsymbol{\theta}$ 的信念：

$$p(\boldsymbol{\theta}|x^{(1)},x^{(2)},...,x^{(m)})=\frac{p(x^{(1)},x^{(2)},...,x^{(m)}|\boldsymbol{\theta})\cdot p(\boldsymbol{\theta})}{p(x^{(1)},x^{(2)},...,x^{(m)})}\propto p(x^{(1)},x^{(2)},...,x^{(m)}|\boldsymbol{\theta})\cdot p(\boldsymbol{\theta})$$

当训练数据很有限时，贝叶斯估计通常泛化得很好，但是当训练样本数目很大时，通常会有很大的计算代价

- 最大后验（MAP）估计
  - 实际上就是取 $\argmax\limits_{\boldsymbol{\theta}}p(\boldsymbol{\theta}|x^{(1)},x^{(2)},...,x^{(m)})$，根据上述推导：

$$\argmax\limits_{\boldsymbol{\theta}}p(\boldsymbol{\theta}|\bold{x})=\argmax\limits_{\boldsymbol{\theta}}(\log p(\bold{x}|\boldsymbol{\theta})+\log p(\boldsymbol{\theta}))$$
